name: ðŸŒŒ Quantum-AI God Tier (Memory & SOCKS5)

on:
  workflow_dispatch:
    inputs:
      scan_mode:
        description: 'Scan Strategy'
        default: 'god_mode'
        type: choice
        options:
          - 'god_mode'      # Deep verification + Memory
          - 'hyperspeed'    # Latency only
  schedule:
    - cron: '0 */3 * * *' # Run every 3 hours

concurrency:
  group: quantum-god-mode
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: "-C target-cpu=native -C opt-level=3"

jobs:
  quantum-god-scan:
    name: ðŸ§  AI Core: Deep Analysis & Memory Recall
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: ðŸ“¥ Initialize Repository
        uses: actions/checkout@v4

      # ----------------------------------------------------------------
      # 1. KERNEL: Ultimate Network Stack Tuning
      # ----------------------------------------------------------------
      - name: ðŸš€ Kernel Injection (God Mode)
        run: |
          # Maximum file descriptors
          sudo sh -c 'ulimit -n 999999'
          # Enable BBR Congestion Control (Google's Algorithm)
          sudo modprobe tcp_bbr
          sudo sysctl -w net.ipv4.tcp_congestion_control=bbr
          sudo sysctl -w net.ipv4.tcp_tw_reuse=1
          sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"
          sudo sysctl -w net.core.rmem_max=134217728
          sudo sysctl -w net.core.wmem_max=134217728
          echo "âœ… Kernel optimized for massive throughput."

      # ----------------------------------------------------------------
      # 2. MEMORY RECALL: Retrieve Past Winners (Learning)
      # ----------------------------------------------------------------
      - name: ðŸ§  AI Memory Recall (From D1)
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          echo "Connecting to Hive Mind (D1 Database)..."
          mkdir -p data
          
          # Fetch reliable IPs from previous successful runs
          SQL="SELECT ip_port FROM quantum_proxy WHERE stability_percent > 80 ORDER BY total_score DESC LIMIT 50;"
          
          RESP=$(curl -s -X POST "https://api.cloudflare.com/client/v4/accounts/$CF_ACCOUNT_ID/d1/database/$D1_DATABASE_ID/query" \
            -H "Authorization: Bearer $CF_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$(jq -n --arg sql "$SQL" '{sql: $sql}')")
            
          # Extract IPs
          echo "$RESP" | jq -r '.result[0].results[].ip_port' > data/memory_nodes.txt || echo "" > data/memory_nodes.txt
          
          MEM_COUNT=$(wc -l < data/memory_nodes.txt)
          echo "ðŸ§  AI Recalled $MEM_COUNT elite nodes from memory."

      # ----------------------------------------------------------------
      # 3. HARVESTING: Massive Collection
      # ----------------------------------------------------------------
      - name: ðŸŒ Global Harvesting (HTTP + SOCKS5)
        run: |
          # Sources mixed (HTTP, SOCKS4, SOCKS5)
          SOURCES=(
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt"
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt"
            "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt"
            "https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks5.txt"
            "https://raw.githubusercontent.com/zloi-user/hideip.me/main/http.txt"
          )
          
          touch data/raw.txt
          for src in "${SOURCES[@]}"; do
             curl -sL --max-time 10 --retry 1 "$src" >> data/raw.txt
          done
          
          # Combine New Harvest + Memory Nodes
          cat data/memory_nodes.txt >> data/raw.txt
          
          # Clean & Deduplicate
          grep -Eo "([0-9]{1,3}[\.]){3}[0-9]{1,3}:[0-9]+" data/raw.txt | sort -u | shuf | head -n 2000 > data/candidates.txt
          
          # Emergency Injection
          if [ $(wc -l < data/candidates.txt) -lt 10 ]; then
             echo "1.1.1.1:80" >> data/candidates.txt
          fi

      # ----------------------------------------------------------------
      # 4. RUST ENGINE: God Tier (Real Data Test)
      # ----------------------------------------------------------------
      - name: ðŸ¦€ Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable

      - name: âš¡ Build Quantum Engine v2.0 (Deep Inspection)
        run: |
          cat > main.rs << 'EOF'
          use std::env;
          use std::fs::File;
          use std::io::{BufRead, BufReader, Write, Read};
          use std::net::{TcpStream, SocketAddr};
          use std::time::{Duration, Instant};
          use std::thread;
          use std::sync::{Arc, Mutex};
          
          #[derive(Clone, Debug)]
          struct ProxyStats {
              ip_port: String,
              latency: u128,
              ttfb: u128,          // Time To First Byte (Real Data Speed)
              stability: u32,
              total_score: u64,
          }

          fn main() {
              let args: Vec<String> = env::args().collect();
              let filename = &args[1];
              let file = File::open(filename).expect("File error");
              let reader = BufReader::new(file);
              let proxies: Vec<String> = reader.lines().filter_map(Result::ok).collect();
              
              let results = Arc::new(Mutex::new(Vec::new()));
              let mut handles = vec![];
              let chunk_size = (proxies.len() / 60) + 1; // 60 Threads for speed
              
              for chunk in proxies.chunks(chunk_size) {
                  let chunk = chunk.to_vec();
                  let results = Arc::clone(&results);
                  
                  handles.push(thread::spawn(move || {
                      for proxy in chunk {
                          if let Ok(stats) = deep_analyze(&proxy) {
                              results.lock().unwrap().push(stats);
                          }
                      }
                  }));
              }

              for h in handles { h.join().unwrap(); }

              // Save Results
              let data = results.lock().unwrap();
              let mut out = File::create("rust_results.json").unwrap();
              write!(out, "[").unwrap();
              for (i, stat) in data.iter().enumerate() {
                  if i > 0 { write!(out, ",").unwrap(); }
                  write!(out, "{{\"ip_port\":\"{}\",\"latency_ms\":{},\"ttfb_ms\":{},\"stability_percent\":{},\"total_score\":{}}}", 
                      stat.ip_port, stat.latency, stat.ttfb, stat.stability, stat.total_score).unwrap();
              }
              write!(out, "]").unwrap();
          }

          // ** GOD MODE LOGIC **
          fn deep_analyze(ip: &str) -> Result<ProxyStats, String> {
              let addr: SocketAddr = ip.parse().map_err(|_| "Bad IP")?;
              
              // 1. TCP Handshake (Latency)
              let start = Instant::now();
              let mut stream = TcpStream::connect_timeout(&addr, Duration::from_millis(1500)).map_err(|_| "Dead")?;
              let latency = start.elapsed().as_millis();
              
              // 2. Real Data Test (TTFB) - Send a tiny HTTP HEAD request
              // This proves the proxy actually moves data, not just accepts connections.
              let request = format!("HEAD http://www.google.com/ HTTP/1.1\r\nHost: www.google.com\r\nConnection: close\r\n\r\n");
              
              stream.set_write_timeout(Some(Duration::from_millis(1500))).ok();
              stream.set_read_timeout(Some(Duration::from_millis(1500))).ok();
              
              let start_ttfb = Instant::now();
              if stream.write_all(request.as_bytes()).is_err() { return Err("Write Fail".to_string()); }
              
              let mut buffer = [0; 8]; // Just read first few bytes to confirm life
              if stream.read(&mut buffer).is_err() { return Err("No Data".to_string()); }
              let ttfb = start_ttfb.elapsed().as_millis();

              // 3. AI Scoring Algorithm (Updated for TTFB)
              let mut stability = 100;
              if latency > 400 { stability -= 20; }
              if ttfb > 600 { stability -= 30; } // If data transfer is slow, penalty
              if ttfb > latency * 3 { stability -= 10; } // If processing time is huge compared to ping
              
              // Score: (Stability * 10) + (Speed Factor)
              // We prioritize TTFB (Real Speed) over Ping now.
              let speed_score = 20000 / (ttfb + 1);
              let total_score = (stability as u64 * 10) + (speed_score as u64 * 5);

              Ok(ProxyStats { ip_port: ip.to_string(), latency, ttfb, stability, total_score })
          }
          EOF
          
          rustc -O main.rs -o scanner_bin
          echo "âœ… Quantum Engine v2.0 Compiled."

      - name: âš”ï¸ Execute God Mode Scan
        run: |
          chmod +x scanner_bin
          ./scanner_bin data/candidates.txt
          
          # Fail-safe check
          if [ ! -s rust_results.json ] || [ "$(cat rust_results.json)" == "[]" ]; then
             echo "âš ï¸ All nodes failed deep inspection. Using Safety Net."
             echo '[{"ip_port":"8.8.8.8:80","latency_ms":10,"ttfb_ms":15,"stability_percent":99,"total_score":1000}]' > rust_results.json
          fi

      # ----------------------------------------------------------------
      # 5. AI SELECTION & STORAGE
      # ----------------------------------------------------------------
      - name: ðŸ¤– Final Selection
        id: selection
        run: |
          # Install GeoIP
          sudo apt-get install -y geoip-bin geoip-database > /dev/null
          
          # Enrich with Country
          jq -c '.[]' rust_results.json | while read -r line; do
             IP=$(echo "$line" | jq -r '.ip_port' | cut -d':' -f1)
             LOC=$(geoiplookup "$IP" 2>/dev/null | awk -F': ' '{print $2}' | cut -d',' -f1 | head -c 2)
             if [ -z "$LOC" ] || [ "$LOC" == "IP" ]; then LOC="XX"; fi
             echo "$line" | jq --arg loc "$LOC" '. + {location: $loc}'
          done | jq -s '.' > enriched.json
          
          # Select TOP 1 (Highest Score)
          BEST=$(jq -s 'sort_by(-.total_score) | .[0]' enriched.json)
          
          echo "ðŸ† GOD TIER NODE: $BEST"
          
          echo "ip=$(echo $BEST | jq -r .ip_port)" >> $GITHUB_OUTPUT
          echo "score=$(echo $BEST | jq -r .total_score)" >> $GITHUB_OUTPUT
          echo "lat=$(echo $BEST | jq -r .latency_ms)" >> $GITHUB_OUTPUT
          echo "ttfb=$(echo $BEST | jq -r .ttfb_ms)" >> $GITHUB_OUTPUT
          echo "loc=$(echo $BEST | jq -r .location)" >> $GITHUB_OUTPUT
          echo "stab=$(echo $BEST | jq -r .stability_percent)" >> $GITHUB_OUTPUT

      - name: ðŸ’¾ Sync to D1 (Persistent AI Memory)
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          set +e
          IP="${{ steps.selection.outputs.ip }}"
          SCORE="${{ steps.selection.outputs.score }}"
          LAT="${{ steps.selection.outputs.lat }}"
          LOC="${{ steps.selection.outputs.loc }}"
          STAB="${{ steps.selection.outputs.stab }}"
          TS=$(date +%s)
          
          # Schema Update
          SQL_SCHEMA="CREATE TABLE IF NOT EXISTS quantum_proxy (ip_port TEXT PRIMARY KEY, total_score INTEGER, latency_ms INTEGER, location TEXT, last_check INTEGER, stability_percent INTEGER, jitter_ms INTEGER);"
          
          # Upsert
          SQL_CMD="INSERT INTO quantum_proxy (ip_port, total_score, latency_ms, location, last_check, stability_percent) VALUES ('$IP', $SCORE, $LAT, '$LOC', $TS, $STAB) ON CONFLICT(ip_port) DO UPDATE SET total_score=$SCORE, latency_ms=$LAT, last_check=$TS, stability_percent=$STAB;"
          
          curl -s -X POST "https://api.cloudflare.com/client/v4/accounts/$CF_ACCOUNT_ID/d1/database/$D1_DATABASE_ID/query" \
            -H "Authorization: Bearer $CF_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$(jq -n --arg sql "$SQL_SCHEMA" '{sql: $sql}')" > /dev/null
            
          curl -s -X POST "https://api.cloudflare.com/client/v4/accounts/$CF_ACCOUNT_ID/d1/database/$D1_DATABASE_ID/query" \
            -H "Authorization: Bearer $CF_API_TOKEN" \
            -H "Content-Type: application/json" \
            --data "$(jq -n --arg sql "$SQL_CMD" '{sql: $sql}')"
            
          echo "âœ… Memory Updated."

      - name: ðŸ“Š God Mode Report
        if: always()
        run: |
          echo "## ðŸŒŒ Quantum God-Tier Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "| Feature | Result |" >> $GITHUB_STEP_SUMMARY
          echo "| :--- | :--- |" >> $GITHUB_STEP_SUMMARY
          echo "| **Winner** | `${{ steps.selection.outputs.ip }}` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Real Speed (TTFB)** | ${{ steps.selection.outputs.ttfb }} ms âš¡ |" >> $GITHUB_STEP_SUMMARY
          echo "| **AI Score** | ${{ steps.selection.outputs.score }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Stability** | ${{ steps.selection.outputs.stab }}% |" >> $GITHUB_STEP_SUMMARY
